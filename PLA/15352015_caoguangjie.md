<center><font style=font-size:32px>**中山大学移动信息工程本科生实验报告** </font></center>

<div><div style="float:left;">课程名称:*Artificial Intelligence*</div>

|   年级   |      1501       |  专业（方向）   |       移动互联网       |
| :----: | :-------------: | :-------: | :---------------: |
| **学号** |  **15352015**   |  **姓名**   |      **曹广杰**      |
| **电话** | **13727022190** | **Email** | 1553118845@qq.com |

###一、实验题目

<center> <font size=4>感知机算法

Perceptron Learning Algorithm</font> </center>

###二、实现内容

1. 实现PLA原始算法和口袋算法
2. 采用4种指标评价并分析你的实验结果
3. 尝试优化，并对优化后的结果进行分析

####算法原理

&emsp;&emsp; Perceptron算法目前主要用于解决二元分类问题。

&emsp;&emsp;该算法使用的是指数加权平均模型，该模型认为对于数据的分类可以有多个属性信息，而不同的属性信息对数据的分类有不同的影响程度，影响程度高的，就在数据分类的实践中具有更大的权重，也就是有更大的影响力。不同的用于分类的数据同时作用在当前的数据判决上，而这种作用方式是加法，即不同的判决属性都会对当前的判决结果有影响，但是影响或多或少。

&emsp;&emsp;我们的目的正是<u>**为一系列的属性信息寻找最合适的权值**</u>，使得我们的匹配方式可以符合更多的数据——Perceptron所解决的正是这样的问题。

&emsp;&emsp;Perceptron算法所使用的策略是：对每一个属性信息都设置一个权值，形成权值序列。如果用于判断当前数据的权值序列不符合，那么就将<u>*不符合的数据*</u>与<u>当前*权值序列*</u>相加，按心情迭代——这种操作的影响就是使原来的权值序列向其判断失误的数据靠近一点，这样的权值序列就更容易符合这类数据。

####伪代码

```R
从文件中读入数据，初始化
    weight向量 w;
	(迭代次数){
      	if(预测 数据v 出错)	w += v;
    }
	(遍历测试样本){
        switch(预测结果|实际结果)
	      	分类结果计数;
    }
输出数据
```

####关键代码截图

该模块主要分析两个部分：

- 在训练集里修正权值序列的部分
- 修正权值序列的函数

##### 根据训练集数据修正权值序列

初始化的权值序列不一定对实验的结果符合得很好，所以需要对权值序列通过训练集数据进行训练，让其符合得更好：

```c++
int train_shoot = 0;// 预测正确的数目
int pocket_shoot = 0;// 口袋里面的数值信息
vector<double> w_reg, w;
for(int i=0; i<50; i++){
		train_shoot = 0;
		for(int i=0; i<Tuplebase.size(); i++){// 遍历训练集的每一行
			Tuple crt_tp = Tuplebase[i];
          	// 根据训练集数据对权值序列进行迭代修正
			bool shot=crt_tp.multiv(w_reg, true);
          	// multiv函数是进行预测和判断预测结果的函数
			if(shot)	train_shoot++;// 计数
		}
	}
```

在以上情形中，我们为修正行为设定了一个确定的迭代次数，首先这是可行的，但是我们并不知道这种迭代的效果会不会对数据符合得更好。

&emsp;&emsp;所谓符合得更好是说最后的权值信息可以符合大多数的数据——但是有可能在一个迭代操作之后，随着权值序列的迭代修改，正在判断处理的数据符合，但是原来符合的数据变得不符合。这就使得整体上，与这个文件中的所有数据更加不符合。而如果使用口袋算法，可以使得迭代的权值序列越来越符合当前的文件数据：

```c++
	int train_shoot = 0;// 预测正确的数目
	int pocket_shoot = 0;// 口袋里面的数值信息
	/*	如果使用口袋算法	*/
	if(train_shoot > pocket_shoot){
		pocket_shoot = train_shoot;
		w = w_reg;
      	// w 为下一次迭代的初始化序列，w_reg 是当前的序列
	}
```
口袋算法使得我们一直在保存更好的值，这样迭代一定次数之后，我们就可以收获一个反正比原来更加符合的权值序列。

##### 修正权值序列的函数

该函数用于：

1. 计算权值序列与当前各个属性数据的加权求和
2. 根据求和数据对当前的权值序列进行修正

```c++
bool Tuple::multiv(vector<double> &w_set, bool fix){
    vector<double> w = w_set;
    int size = w_set.size();
  	int sign=0;
  	// 为每一个属性信息加权， 实现求和操作
    for(int i=0; i<size; i++)     sign += (xi[i] * w[i]);
    if((sign*label) > 0)   return true;
    else{
      	// 一旦不符合，检查是否有修改权值数组的权限
        if(fix)
            for(int i=0; i<size; i++)
                w_set[i] += label * xi[i];
        return false;
    }
}
```
####创新点与优化

&emsp;&emsp;细化修正行为，使用衰减修正操作的方法。

由结果分析中的初试结果数据可以看出：

- 命中率随着迭代次数的上升而产生波动，并非上升趋势
- 在迭代次数到达一定的程度之后，命中率就会趋于稳定
- 在命中率上升的阶段，准确率有明显的波动情况

笔者关注到这里的准确率的波动情况，这种波动而不是攀升说明了在开始条件下，数据迭代更新的程度过大，权值集合的校正过于明显。而这种情况可能引起的后果就是，在迭代的最后阶段，数据已经趋于稳定——但是事实上，也许在最后阶段我们的计算已经错过了一些很重要的符合位置。

<img width="400" src="https://imgsa.baidu.com/forum/pic/item/312f064a20a44623ce0555379322720e0df3d7a2.jpg" />

我们最后的迭代拟合一直处于在黄线和绿线的两个选项中跳转，很少有能够到达黑线的数据——然而事实上，黑线的权值向量才是分类的最优解。

&emsp;&emsp;为此，削弱在修正过程中可能会出现的巨大波动或许会对提高整体预测准确率有积极影响，修改修正当前权值序列的函数如下：

```c++
vector<double> w_set;// 权值序列
for(int i=0; i<size; i++){
    double insert = label * xi[i];
    w_set[i] += 0.3*insert;
    //w_set[i] += insert; 未修改时候的修正
}
```

####三、实验结果与分析

#####实验结果示例展示

小数据集定性测试。

<img width="650" src="https://imgsa.baidu.com/forum/pic/item/81591f4e9258d109893920e4da58ccbf6d814d9f.jpg" />

由于本次实验实现的是二元分类的操作，由前置的65个维度或者65个属性对最后的label进行判定。笔者设置了训练集中的5个数据：

- 后35至30个维度为1，前30个维度为0的属性集合，决定标签为1
- 后35至30个维度为0，前30个维度为1的属性集合，决定标签为-1

这种方式符合65维度中的分类要求，因为所属的数据大都不分布在同一个维度。

测试集的数据，笔者选择后10个维度为1的，label为1的数据——分类结果符合期望。

#####评测指标展示及分析

在一定范围内进行迭代次数的调试的时候，不同的迭代次数就会对应不同的准确率。这里使用口袋算法加快数据模型的收敛，获得迭代次数与准确率的对应关系：

```c++
校正集的 迭代次数
正确个数
824		---1000
824		---900 
824		---500
827		---300
846		---200
835		---100
844		---50 
837		---10
826		---5
839		---3
838		---1
```

此时笔者实现的是尚未优化的测试数据结果。

- 命中率随着迭代次数的上升而产生波动，并非上升趋势
- 在迭代次数到达一定的程度之后，命中率就会趋于稳定
- 在命中率上升的阶段，准确率有明显的波动情况

&emsp;&emsp;基于优化方案中所讨论的推论，笔者对修正权值序列的集合中对修正程度做了衰减处理。

```sql
0.3倍衰减				0.5倍衰减
训练 校正 迭代		  训练 校正 迭代
3254 790 100            3240 843 100
3255 818 200           3254 "846" 200
3255 818 300            3254 846 250
3263 802 400            3260 828 300
3267 "848" 500          3260 828 400
 3267 848 600          3265 "846" 500
3272 "839" 700         3265 "846" 600
3272 "839" 800         3265 "846" 700
```

可以看到在0.5倍衰减的时候，最高值可以达到846，而在0.3倍衰减的时候，最大值可以达到更高，这说明衰减操作在提高整体预测率的角度上是有效的。

###### 测评指标分析

- 迭代次数均为500次的情况

0.3倍衰减：

```sql
Accuracy=0.806450
Recall=0.074941
Precision=0.382711
F1=0.125339
```

无衰减：

```sql
Accuracy=0.806301
Recall=0.074863
Precision=0.382233
F1=0.125203
```

可以看到四个评测指标都有同比的增长，尽管增长的幅度不是很大——在衰减之后的迭代中，收敛速度会比为衰减的情况收敛速度更慢一些——但是比较来看，增长的事实还是很明显的。

在衰减之后，优化的算法不再纠结于是使得筛选条件更加严苛还是更加宽松的问题上，而是把注意力放在如何更加仔细地找到合适的筛选条件，随着迭代的继续，筛选条件逐步细化，开始为适应不同的数据进行微调，使得评测指标均有上升。

- 这种优化的结果，很显然会加大计算量，因为收敛速度更慢
- 有可能导致过拟合，因为权值序列为了符合当前的数据而进行了过多针对性的修正，这种修正很显然不一定适合其他的测试数据。

####四、思考

1. 有什么其他的手段可以解决数据集非线性可分的问题？

   所谓数据未必线性可分，即分界线也许不是通过权值相加而得到的。

   1. 使用多个线性模型对非线性数据集进行拟合，在二维中表示就是使用多条短线段勾画出曲线的轮廓，以适应数据的分类
   2. 更换数学模型吧那就，如果直线不能拟合当前的数据分离问题，也许加权过程需要控制，或者加权之后不直接使用线性相加，也可以符合更为复杂的模型
   3. 使用网格分类，将维度的映射划分为网格，随着各种属性的相似度，将小规模的网格拼接成大规模的网格，以此实现更加复杂的分类

2. 请查询相关资料，解释为什么要用这四种评测指标，各自的意义是什么

   Accuracy：表征整体上预测准确的比例

   Precision：表征在预测结果为positive的情况下的准确率

   Recall：对所有本质是positive的结果的准确度，或者在所有目标（笔者以positive为目标）中选中的比例

   F1得仔细解释一下：

   - 在筛选条件严苛的时候准确率Precision就会上升，因为只有特别典型的positive才能入选
   - 在筛选条件严苛时，召回率(Recall)就会下降，因为有更多的可能并非是positive的数据入选
   - 筛选条件宽松的时候二者相反

   &emsp;&emsp;综上，筛选条件的选择并不容易选取，或者过高或者过低。这些情况下，Precision和Recall都是此消彼长的关系，难以兼得。而F1：

   ```sql
   F1 = (2 * precision * recall) / (precision + recall)
   ```

   则是对两者进行统一的处理，这里面用到一个二元一次不等式的性质，使得只有在precision与recall都升高，**而且**，升高比例都相近的时候，F1值才会取得更大的值。故而，把F值作为两个参数的综合指标评测。

   *查阅资料：<http://blog.csdn.net/maria5201314/article/details/53484463>*

   <div><div style="float:right;"><font size=0.01> 幸好不用写实验感想 </font></div>

   ​